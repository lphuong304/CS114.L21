{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoFinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lphuong304/CS114.L21/blob/main/FINAL_PROJECT/DemoFinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-n3tPtnWZec"
      },
      "source": [
        "<h1 align=\"center\"><b>Đồ án cuối kỳ môn Máy học - CS112.L21</b></h1>\n",
        "<h1 align=\"center\"><b>MÔ HÌNH SIÊU THỊ KHÔNG THU NGÂN TRONG BỐI CẢNH THANH TOÁN ĐIỆN TỬ PHÁT TRIỂN MẠNH (BÀI TOÁN NHẬN DIỆN SẢN PHẨM THƯƠNG MẠI)</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca04d1GlbmC6"
      },
      "source": [
        "## 1. Giới thiệu\n",
        "* Bộ môn: Máy học - CS112.L21\n",
        "* Giảng viên:\n",
        "  * Lê Đình Duy\n",
        "  * Phạm Nguyễn Trường An\n",
        "* Thành viên nhóm:\n",
        "  * Nguyễn Ngọc Lan Phương - 19520227 (Leader)\n",
        "  * Nguyễn Quốc Huy - 19521623\n",
        "  * Hoàng Anh Tú - 19522450\n",
        "* Credit:\n",
        "1. [paper predict retail production](https://core.ac.uk/download/pdf/218819449.pdf)\n",
        "2. [deepsort](https://github.com/nwojke/deep_sort)\n",
        "3. [faster rcnn vs yolo](https://everitt257.github.io/post/2018/08/10/object_detection.html#:~:text=YOLO%20stands%20for%20You%20Only,regression%20at%20the%20same%20time.)\n",
        "4. [transfer learning](https://vankhangfet.github.io/2018-10-30-transfer-learning/)\n",
        "5. [detectron2](https://github.com/facebookresearch/detectron2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIFScBAjM_g"
      },
      "source": [
        "#2. Mô tả bài toán:\n",
        "* **Bối cảnh ứng dụng**: Trong thời đại công nghệ phát triển vượt trội,nhu cầu mua sắm của con người ngày càng cao, song song với sự phát triển mạnh mẽ của thương mại điện tử thì hình thức mua sắm truyền thống vẫn là sự lựa chọn hàng đầu của con người. Dựa trên điều đó, chúng em nảy ra ý tưởng vận dụng Machine Learning hay cụ thể hơn là Deep Learning vào MÔ HÌNH SIÊU THỊ KHÔNG THU NGÂN thông qua bài toán nhận diện sản phẩm thương mại.\n",
        "* **Tại sao lại là MÔ HÌNH SIÊU THỊ KHÔNG THU NGÂN? Lợi ích so với mô hình truyền thống?**\n",
        " Sản phẩm đồ án của chúng em sẽ mang đến những lợi ích như sau:\n",
        "  + Giúp đẩy nhanh quy trình thanh thoán tại các cửa hàng, hạn chế việc chờ đợi xếp hàng. (Vì tốc độ của máy nhanh hơn thủ công)\n",
        "  + Cắt giảm chi phí nhân lực, giảm các trường hợp dịch vụ không được đánh giá cao do thái độ nhân viên.\n",
        "  + Tối ưu hóa trải nghiệm người dùng ở quá trình thanh toán.\n",
        "  + Đáng tin cậy hơn so với hình thức thanh toán thủ công\n",
        "* **INPUT**: Video thời lượng tối đa 1 phút các sản phẩm thương mại, góc quay từ trên xuống, mặt hàng đặt nằm ngửa, quay trực diện sản phẩm, ánh sáng tốt (xét điều kiện ánh sáng siêu thị), mỗi mặt hàng có nhiều mặt (trước, sau), video không nhiễu, chất lượng video tối thiểu là 480p trở lên.\n",
        "* **OUTPUT**: Tên sản phẩm thương mại + Số lượng + Gía tiền sản phẩm => Tổng tiền (Hình thức một hóa đơn)\n",
        "\n",
        "<a align = center>\n",
        "  <img src='https://drive.google.com/uc?export=view&id=1J9GDyPSjU-ka3o_NgELDZTFVgCeCmQWZ' align = center>\n",
        "  <div style=width: 130px; align = center>Ảnh thực tế: nhân viên thu ngân ở siêu thị</div>\n",
        "</a>\n",
        "\n",
        "<a align = center>\n",
        "  <img src='https://drive.google.com/uc?export=view&id=1WK7Ye8RuHFMncvd6EaA5Ccu2k2anw8Ij' style='width: 140px' align = center>\n",
        "  <div style=width: 130px; align = center>Ảnh minh họa: hoạt động của ứng dụng trong thực tế</div>\n",
        "</a>\n",
        "\n",
        "* **CÁCH LẤY DỮ LIỆU**: Vì dịch bệnh không cho phép nên chúng em sẽ ưu tiên đến siêu thị gần nhà và sẽ ưu tiên chủ yếu lấy data ở thương hiệu siêu thị đã thống nhất => Siêu thị Bách Hóa Xanh. Thu thập giá và tên sản phẩm thương mại từ web thương mại điện tử (www.bachhoaxanh.com), \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43M0eohkVEKy"
      },
      "source": [
        "#3. MÔ TẢ BỘ DỮ LIỆU:\n",
        "##3.1 Dữ liệu và cách thu thập:\n",
        "Chúng em sẽ tiến hàng nhận diện **198** sản phẩm khác nhau, chủ yếu là các mặt hàng thuộc thuộc loại nước giải khát, bánh kẹo, thực phẩm ăn liền, các dụng cụ gia dụng được bày bán ở Bách Hóa Xanh là chủ yếu.\n",
        "\n",
        "<a align = center>\n",
        "  <img src='https://drive.google.com/uc?export=view&id=1pklFqjhCPdWr9R_Sfl89YV13QB5g5Nnd' style='width: 140px' align = center>\n",
        "  <div style=width: 130px; align = center>Ảnh minh họa: Ví dụ về các sản phẩm thuộc Siêu Thị Bách Hóa Xanh</div>\n",
        "</a>\n",
        "\n",
        "* Bộ dữ liệu dự tính sẽ bao gồm: \n",
        "  + Một dataset dạng bảng hiển thị tên sản phẩm + giá được cập nhật gần nhất với thời gian báo cáo đồ án được crawl từ web.  \n",
        "  + Tập dữ liệu hình dùng để train: **19050** hình tự chụp cho 198 classes, trung bình **90-100 tấm hình/class** (hình ảnh do **NHÓM TỰ CHỤP**)\n",
        "  + Bộ data để test của nhóm bao gồm **10-20** videos nhóm tự quay các sản phẩm thương mại có trong tập train với điều kiện đã ràng buộc như trên (*hoàn toàn hợp lý với điều kiện video sản phẩm đặt ở quầy thu ngân*). \n",
        "  \n",
        "##3.2 Các thao tác tiền xử lý dữ liệu:\n",
        "* Nhóm dụ định sẽ dùng model **YOLO** và **DETECTRON2(FASTER RCNN)** để train, cụ thể hơn, đối với model **YOLO** nhóm sẽ dùng hai model là **YOLOV3** và **YOLOV4** để train để có thể đánh giá kết quả một cách tốt nhất**\n",
        "* Toàn bộ các pipelines, data của nhóm đều được lưu trữ trong một folder drive duy nhất để nhóm tiện trao đổi với nhau.\n",
        "* Đối với từng model như trên, nhóm cũng có cách tiền xử lý dữ liệu riêng cho từng model khác nhau, cụ thểm với:\n",
        " + YOLOV3 và YOLOV4: Sử dụng tool labelImg để label từng ảnh với nhãn tương đương ([link tool labelImg](https://github.com/tzutalin/labelImg)). Sau khi label xong, tương ứng với mỗi file hình sẽ có một file txt trùng tên. Sau đó gộp tất cả file hình và file txt lại với nhau để đưa lên p Trong file txt cụ thể như sau:\n",
        " + class: là một số tự nhiên đánh số thứ tự của nhãn. Ví dụ số classes của nhóm em là 198, thì Bánh Pocky Hương Dâu sẽ là 0, Bánh Pocky Hương Socola là 1, vv...vv\n",
        " + x, y, height, width là các giá trị thập phân liên quan đến vị trí của hình và nằm trong khoảng 0 đến 1 và được tính toán như sau:\n",
        "    + x = <tọa độ trung tâm của sản phẩm theo trục x> / <chiều rộng hình>\n",
        "    + y = <tọa độ trung tâm của vật thể theo phương x> / <chiều cao hình>\n",
        "    + width = <chiều rộng thực của bounding box> / <chiều rông hình>\n",
        "    + height = <chiều cao thực của bounding box> / <chiều cao hình>\n",
        " + DETECTRON2(FASTER RCNN): Nhóm sẽ sử dụng tool để convert các file txt trên sang dạng format file xml, đưa tất cả file này về định dạng json và đưa lên model để train. Sau khi convert file xml sẽ bao gồm các keys lần lượt là:\n",
        "     + Tên file\n",
        "     + Label có trong file hình trên (đánh số tương tự như đối với yolo)\n",
        "     + Width, height, depth của object\n",
        "     + Các tọa độ xmax, ymax, xmin, ymin của bounding box.\n",
        "\n",
        "##3.3 Phân chia (split) - train/dev/test\n",
        "Như đã đề cập bên trên trong quá trình train, chúng em sẽ chia bộ data theo theo tỉ lệ 80/20 một cách ngẫu nhiên đối với tập train và valid. Sau đó chúng em sẽ đem model đó về máy local, đua vào code detect đối với các videos test chúng em tự quay.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr4pT764a7z5"
      },
      "source": [
        "#4. Mô Tả Đặc Trưng \n",
        "Thông qua tìm hiểu chúng em sẽ sử dụng kỹ thuật Transfer Learning, dùng pretrained model trên tính tập dataset của riêng chúng em để có thể tận dụng những ưu điểm như điểm khởi đầu của accuracy tốt, tốc độ accuracy tăng nhanh, đường tiệm cận hiệu quả hơn, chính xác hơn, quan trọng hơn Transfer Learning là một phương pháp giúp chúng em có một model tốt hơn hẳn dựa trên bộ dữ liệu khá ít ỏi mà chúng em tìm được.\n",
        "\n",
        "Chúng em sẽ sử dụng kỹ thuật **Feature extractor** của Transfer Learning để tự lấy ra các đặc điểm của ảnh bằng việc sử dụng ConvNet của pre-trained model.\n",
        "\n",
        "[Link tham khảo](https://vankhangfet.github.io/2018-10-30-transfer-learning/)\n",
        "\n",
        "+ Đối với Yolov4 chúng em sẽ sử dụng pretrained weights yolov4.conv.137\n",
        "\n",
        "+ Đối với Yolov3, chúng em sẽ sử dụng pretrained weights darknet53.conv.74\n",
        "\n",
        "+ Đối với Detectron2(Faster Rcnn), chúng em sẽ sử dụng pretrained weights resnet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h7en8rzbE9X"
      },
      "source": [
        "#5. Mô Tả Thuật Toán Dùng Để Train Model\n",
        "* Yolov3 VÀ Yolov4:\n",
        "Nhìn chung cả hai mô hình đều sử dụng gần chung một kiến trúc:\n",
        " + Logistic regression: để predict độ tự tin của bounding box liệu có chứa object hay không.\n",
        " + Logistic Classifier rời rạc: để classify các object.\n",
        " + Backbone: dùng darnknet - 53\n",
        " + Multi-scaled prediction: dùng kiến trúc [Feature Pyramid Networks (FPN)](https://arxiv.org/abs/1612.03144) để dự đoán các scale.\n",
        " + Skip-layer concatenation: tạo thêm liên kết giữa các layers dự đoán.\n",
        "\n",
        "Tuy nhiên Yolov4 sẽ cải tiến tốc độ so với Yolov3.\n",
        "\n",
        "* Faster RCNN sử dụng framwork **detectron2**:\n",
        " + Cải tiến từ RCNN và Fast RCNN, Faster RCNN không sử dụng selective search để lấy ra các bouding box có khả năng chứa các object mà sẽ áp dụng thêm một mạng CNN mới để tìm.\n",
        " + Tất cả ảnh sẽ được cho qua pretrain-model để lấy feature map. Sau đó, thực hiện tính toán để detect object.\n",
        "\n"
      ]
    }
  ]
}